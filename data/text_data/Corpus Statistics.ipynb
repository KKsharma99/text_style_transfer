{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:08<00:00,  2.09it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 47.48it/s]\n",
      "100%|██████████| 58/58 [00:00<00:00, 78.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown, gutenberg, inaugural, stopwords\n",
    "# Number of Sentences, Word Frequency, Mean Sentence Length\n",
    "from tqdm import tqdm\n",
    "import string \n",
    "\n",
    "num_sents_arr = []\n",
    "num_vocab_arr = []\n",
    "mean_size_arr = []\n",
    "avg_word_freq = []\n",
    "tot_word_freq = {}\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "for fileid in tqdm(gutenberg.fileids()):\n",
    "    if fileid == 'bible-kjv.txt' or 'shakespeare' in fileid:\n",
    "        continue\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid))) \n",
    "    \n",
    "    for curr_word in gutenberg.words(fileid):\n",
    "        curr_word = curr_word.lower()\n",
    "        if curr_word not in string.punctuation and curr_word not in stopwords:\n",
    "            if curr_word in tot_word_freq:\n",
    "                tot_word_freq[curr_word] += 1\n",
    "            else:\n",
    "                tot_word_freq[curr_word] = 1\n",
    "    \n",
    "    num_sents_arr.append(num_sents)\n",
    "    mean_size_arr.append(num_words / num_sents)\n",
    "    num_vocab_arr.append(num_vocab)\n",
    "    avg_word_freq.append(num_words / num_vocab)\n",
    "    \n",
    "    # average sentence length, and the number of times each vocabulary item appears in the text on average \n",
    "#     print(round(num_words/num_sents), round(num_words/num_vocab), fileid)\n",
    "\n",
    "for fileid in tqdm(brown.fileids()):\n",
    "    num_words = len(brown.words(fileid))\n",
    "    num_sents = len(brown.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in brown.words(fileid)))\n",
    "    \n",
    "    for curr_word in brown.words(fileid):\n",
    "        curr_word = curr_word.lower()\n",
    "        if curr_word not in string.punctuation and curr_word not in stopwords:\n",
    "            if curr_word in tot_word_freq:\n",
    "                tot_word_freq[curr_word] += 1\n",
    "            else:\n",
    "                tot_word_freq[curr_word] = 1\n",
    "    \n",
    "    num_sents_arr.append(num_sents)\n",
    "    mean_size_arr.append(num_words / num_sents)\n",
    "    num_vocab_arr.append(num_vocab)\n",
    "    avg_word_freq.append(num_words / num_vocab)\n",
    "    \n",
    "    # average sentence length, and the number of times each vocabulary item appears in the text on average \n",
    "#     print(round(num_words/num_sents), round(num_words/num_vocab), fileid) \n",
    "\n",
    "for fileid in tqdm(inaugural.fileids()):\n",
    "    if fileid == '2017-Trump.txt':\n",
    "        continue\n",
    "    num_words = len(inaugural.words(fileid))\n",
    "    num_sents = len(inaugural.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in inaugural.words(fileid)))\n",
    "    \n",
    "    for curr_word in inaugural.words(fileid):\n",
    "        curr_word = curr_word.lower()\n",
    "        if curr_word not in string.punctuation and curr_word not in stopwords:\n",
    "            if curr_word in tot_word_freq:\n",
    "                tot_word_freq[curr_word] += 1\n",
    "            else:\n",
    "                tot_word_freq[curr_word] = 1\n",
    "    \n",
    "    num_sents_arr.append(num_sents)\n",
    "    mean_size_arr.append(num_words / num_sents)\n",
    "    num_vocab_arr.append(num_vocab)\n",
    "    avg_word_freq.append(num_words / num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of sentences is 123573.\n",
      "The total number of unique words is 524390.\n",
      "The mean sentence length is 22.931426.\n",
      "The mean number of times each vocab word appears in this corporus is 3.405128.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('--', 9240),\n",
       " ('``', 8837),\n",
       " (\"''\", 8791),\n",
       " ('one', 7678),\n",
       " ('said', 7388),\n",
       " ('would', 6350),\n",
       " ('.\"', 5820),\n",
       " ('could', 5035),\n",
       " (',\"', 4723),\n",
       " ('man', 4050),\n",
       " ('like', 3989),\n",
       " ('time', 3782),\n",
       " ('little', 3665),\n",
       " ('must', 3447),\n",
       " ('well', 3131),\n",
       " ('may', 3124),\n",
       " ('see', 3005),\n",
       " ('much', 2973),\n",
       " ('two', 2952),\n",
       " ('good', 2910),\n",
       " ('first', 2907),\n",
       " ('know', 2904),\n",
       " ('great', 2820),\n",
       " ('upon', 2705),\n",
       " ('never', 2577),\n",
       " ('made', 2559),\n",
       " ('us', 2504),\n",
       " ('new', 2498),\n",
       " ('every', 2439),\n",
       " ('old', 2402)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import heappush, nlargest\n",
    "\n",
    "'''\n",
    "PROCESS TOTAL ENG CORPUS STATISTICS -- AMONG ALL CORPORA\n",
    "'''\n",
    "\n",
    "tot_sents = sum(num_sents_arr)\n",
    "print('The total number of sentences is %d.' %tot_sents)\n",
    "tot_vocab = sum(num_vocab_arr)\n",
    "print('The total number of unique words is %d.' %tot_vocab)\n",
    "mean_sent_size = sum(mean_size_arr)/len(mean_size_arr)\n",
    "print('The mean sentence length is %f.' %mean_sent_size)\n",
    "mean_vocab_size = sum(avg_word_freq)/len(avg_word_freq)\n",
    "print('The mean number of times each vocab word appears in this corporus is %f.'%mean_vocab_size)\n",
    "\n",
    "word_freq = []\n",
    "for key, value in tot_word_freq.items():\n",
    "    heappush(word_freq, (key, value))\n",
    "nlargest(30, word_freq, key=lambda r:r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known pre-processing: Lower-case all words for consistency. Filter for punctuation and stop-words. Delete Trump's inauguration address.\n",
    "\n",
    "Filter out Bible, Shakespeare pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Sentences, Word Frequency, Mean Sentence Length\n",
    "\n",
    "trump_dat = open('/Users/schen1337/Documents/text_style_transfer/data/text_data/orig/trump_all_data.txt', 'rb')\n",
    "\n",
    "num_words = 0\n",
    "num_sents = 0\n",
    "num_vocab = set()\n",
    "\n",
    "mean_sents_size = []\n",
    "mean_vocab_size = []\n",
    "\n",
    "tot_word_freq = {}\n",
    "\n",
    "for line in trump_dat:\n",
    "    num_sents += 1\n",
    "    for word in line.split(b' '):\n",
    "        try: \n",
    "            word = word.decode(\"utf-8\") \n",
    "        except:\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        num_words += 1\n",
    "        num_vocab.add(word)\n",
    "        if word not in string.punctuation and word not in stopwords:\n",
    "            if word in tot_word_freq:\n",
    "                tot_word_freq[word] += 1\n",
    "            else:\n",
    "                tot_word_freq[word] = 1\n",
    "    mean_sents_size.append(num_words / num_sents)\n",
    "    mean_vocab_size.append(num_words / len(num_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of sentences is 25038.\n",
      "The total number of unique words is 16022.\n",
      "The mean sentence length is 10.279577.\n",
      "The mean number of times each vocab word appears in this corporus is 11.922328.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('going', 2585),\n",
       " ('people', 1306),\n",
       " ('—', 1257),\n",
       " ('want', 973),\n",
       " ('know', 874),\n",
       " ('dont', 858),\n",
       " ('think', 853),\n",
       " ('it.\\n', 848),\n",
       " ('get', 827),\n",
       " ('great', 822),\n",
       " ('like', 812),\n",
       " ('one', 780),\n",
       " ('im', 759),\n",
       " ('theyre', 670),\n",
       " ('know,', 657),\n",
       " ('said', 536),\n",
       " ('go', 532),\n",
       " ('said,', 532),\n",
       " ('would', 531),\n",
       " ('many', 512),\n",
       " ('\\n', 488),\n",
       " ('thats', 488),\n",
       " ('lot', 486),\n",
       " ('thank', 486),\n",
       " ('say', 485),\n",
       " ('make', 474),\n",
       " ('got', 466),\n",
       " ('really', 438),\n",
       " ('country', 423),\n",
       " ('that.\\n', 422)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PROCESS TOTAL TRUMP CORPUS STATISTICS -- AMONG ALL CORPORA\n",
    "'''\n",
    "\n",
    "print('The total number of sentences is %d.' %num_sents)\n",
    "print('The total number of unique words is %d.' %len(num_vocab))\n",
    "mean_sents_size = sum(mean_sents_size)/len(mean_sents_size)\n",
    "print('The mean sentence length is %f.' %mean_sents_size)\n",
    "mean_vocab_size = sum(mean_vocab_size)/len(mean_vocab_size)\n",
    "print('The mean number of times each vocab word appears in this corporus is %f.'%mean_vocab_size)\n",
    "\n",
    "word_freq = []\n",
    "for key, value in tot_word_freq.items():\n",
    "    heappush(word_freq, (key, value))\n",
    "nlargest(30, word_freq, key=lambda r:r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit5a06139154784f7082b34e4572a2fa43"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
