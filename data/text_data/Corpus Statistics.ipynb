{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:08<00:00,  2.08it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 47.32it/s]\n",
      "100%|██████████| 58/58 [00:00<00:00, 82.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown, gutenberg, inaugural, stopwords\n",
    "# Number of Sentences, Word Frequency, Mean Sentence Length\n",
    "from tqdm import tqdm\n",
    "import string \n",
    "\n",
    "num_sents_arr = []\n",
    "num_vocab_arr = []\n",
    "mean_size_arr = []\n",
    "avg_word_freq = []\n",
    "tot_word_freq = {}\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "for fileid in tqdm(gutenberg.fileids()):\n",
    "    if fileid == 'bible-kjv.txt' or 'shakespeare' in fileid:\n",
    "        continue\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid))) \n",
    "    \n",
    "    for curr_word in gutenberg.words(fileid):\n",
    "        curr_word = curr_word.lower()\n",
    "        if curr_word not in string.punctuation and curr_word not in stopwords:\n",
    "            if curr_word in tot_word_freq:\n",
    "                tot_word_freq[curr_word] += 1\n",
    "            else:\n",
    "                tot_word_freq[curr_word] = 1\n",
    "    \n",
    "    num_sents_arr.append(num_sents)\n",
    "    mean_size_arr.append(num_words / num_sents)\n",
    "    num_vocab_arr.append(num_vocab)\n",
    "    avg_word_freq.append(num_words / num_vocab)\n",
    "    \n",
    "    # average sentence length, and the number of times each vocabulary item appears in the text on average \n",
    "#     print(round(num_words/num_sents), round(num_words/num_vocab), fileid)\n",
    "\n",
    "for fileid in tqdm(brown.fileids()):\n",
    "    num_words = len(brown.words(fileid))\n",
    "    num_sents = len(brown.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in brown.words(fileid)))\n",
    "    \n",
    "    for curr_word in brown.words(fileid):\n",
    "        curr_word = curr_word.lower()\n",
    "        if curr_word not in string.punctuation and curr_word not in stopwords:\n",
    "            if curr_word in tot_word_freq:\n",
    "                tot_word_freq[curr_word] += 1\n",
    "            else:\n",
    "                tot_word_freq[curr_word] = 1\n",
    "    \n",
    "    num_sents_arr.append(num_sents)\n",
    "    mean_size_arr.append(num_words / num_sents)\n",
    "    num_vocab_arr.append(num_vocab)\n",
    "    avg_word_freq.append(num_words / num_vocab)\n",
    "    \n",
    "    # average sentence length, and the number of times each vocabulary item appears in the text on average \n",
    "#     print(round(num_words/num_sents), round(num_words/num_vocab), fileid) \n",
    "\n",
    "for fileid in tqdm(inaugural.fileids()):\n",
    "    num_words = len(inaugural.words(fileid))\n",
    "    num_sents = len(inaugural.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in inaugural.words(fileid)))\n",
    "    \n",
    "    for curr_word in inaugural.words(fileid):\n",
    "        curr_word = curr_word.lower()\n",
    "        if curr_word not in string.punctuation and curr_word not in stopwords:\n",
    "            if curr_word in tot_word_freq:\n",
    "                tot_word_freq[curr_word] += 1\n",
    "            else:\n",
    "                tot_word_freq[curr_word] = 1\n",
    "    \n",
    "    num_sents_arr.append(num_sents)\n",
    "    mean_size_arr.append(num_words / num_sents)\n",
    "    num_vocab_arr.append(num_vocab)\n",
    "    avg_word_freq.append(num_words / num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of sentences is 123663.\n",
      "The total number of unique words is 524937.\n",
      "The mean sentence length is 22.924222.\n",
      "The mean number of times each vocab word appears in this corporus is 3.404586.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('--', 9240),\n",
       " ('``', 8837),\n",
       " (\"''\", 8791),\n",
       " ('one', 7686),\n",
       " ('said', 7388),\n",
       " ('would', 6350),\n",
       " ('.\"', 5821),\n",
       " ('could', 5035),\n",
       " (',\"', 4723),\n",
       " ('man', 4050),\n",
       " ('like', 3991),\n",
       " ('time', 3784),\n",
       " ('little', 3666),\n",
       " ('must', 3450),\n",
       " ('well', 3131),\n",
       " ('may', 3124),\n",
       " ('see', 3005),\n",
       " ('much', 2974),\n",
       " ('two', 2953),\n",
       " ('good', 2913),\n",
       " ('first', 2911),\n",
       " ('know', 2904),\n",
       " ('great', 2826),\n",
       " ('upon', 2705),\n",
       " ('never', 2583),\n",
       " ('made', 2561),\n",
       " ('us', 2506),\n",
       " ('new', 2504),\n",
       " ('every', 2446),\n",
       " ('old', 2404)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import heappush, nlargest\n",
    "\n",
    "'''\n",
    "PROCESS TOTAL ENG CORPUS STATISTICS -- AMONG ALL CORPORA\n",
    "'''\n",
    "\n",
    "tot_sents = sum(num_sents_arr)\n",
    "print('The total number of sentences is %d.' %tot_sents)\n",
    "tot_vocab = sum(num_vocab_arr)\n",
    "print('The total number of unique words is %d.' %tot_vocab)\n",
    "mean_sent_size = sum(mean_size_arr)/len(mean_size_arr)\n",
    "print('The mean sentence length is %f.' %mean_sent_size)\n",
    "mean_vocab_size = sum(avg_word_freq)/len(avg_word_freq)\n",
    "print('The mean number of times each vocab word appears in this corporus is %f.'%mean_vocab_size)\n",
    "\n",
    "word_freq = []\n",
    "for key, value in tot_word_freq.items():\n",
    "    heappush(word_freq, (key, value))\n",
    "nlargest(30, word_freq, key=lambda r:r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known pre-processing: Filter for punctuation, stop-words, and lower-case all words for consistency.\n",
    "\n",
    "Filter out Bible, Shakespeare pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit5a06139154784f7082b34e4572a2fa43"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
